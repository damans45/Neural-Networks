{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000)\n",
      "(70000, 1)\n",
      "(1, 70000)\n",
      "[['5' '0' '4' ... '4' '5' '6']]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.T.shape)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Normalize\n",
    "X = X/255\n",
    "print(type(y[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  weâ€™re just building a zero-classifier for now. So we want our labels to say 1 when we have a zero, and 0 otherwise\n",
    "\n",
    "y_new = np.zeros((y.shape[0],1))\n",
    "y_new[y == '0'] = 1\n",
    "y_new[y != '0'] = 0\n",
    "y_new.shape\n",
    "y = y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data --> each example in a column instead of a row\n",
    "\n",
    "m = 60000\n",
    "m_test = X.shape[0] - m\n",
    "\n",
    "X_train, X_test = X[:m].T, X[m:,].T\n",
    "y_train, y_test = y[:m].reshape(1, m), y[m:].reshape(1,m_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000)\n",
      "(784, 10000)\n",
      "(1, 60000)\n",
      "(1, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # One example in each column\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the training set\n",
    "np.random.seed(138)\n",
    "shuffle_index = np.random.permutation(m)\n",
    "X_train, y_train = X_train[:,shuffle_index], y_train[:,shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random image\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i = 40\n",
    "plt.imshow(X_train[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
    "print(y_train[:,i])\n",
    "\n",
    "# label is 0, because we are just training a binary classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Single Neuron ( Logistic Regression) - Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n",
    "def compute_loss(Y,Y_hat):\n",
    "    m = Y.shape[1]\n",
    "    L = -(1 / m) * np.sum ( (Y * np.log(Y_hat)) + ((1 - Y) * np.log(1 - Y_hat))  )\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :  0 cost :  0.6840801595436431\n",
      "Iteration :  100 cost :  0.10781549403603288\n",
      "Iteration :  200 cost :  0.08245533921989824\n",
      "Iteration :  300 cost :  0.07142765065115936\n",
      "Iteration :  400 cost :  0.06485584350261014\n",
      "Iteration :  500 cost :  0.06036454927983813\n",
      "Iteration :  600 cost :  0.05704607944076546\n",
      "Iteration :  700 cost :  0.0544660009146988\n",
      "Iteration :  800 cost :  0.05238622282817923\n",
      "Iteration :  900 cost :  0.05066378415961421\n",
      "Iteration :  1000 cost :  0.04920697012059556\n",
      "Iteration :  1100 cost :  0.04795389640787956\n",
      "Iteration :  1200 cost :  0.04686110603804828\n",
      "Iteration :  1300 cost :  0.04589707543148204\n",
      "Iteration :  1400 cost :  0.04503831260139265\n",
      "Final cost -  0.04427423766197228\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.05\n",
    "\n",
    "X = X_train\n",
    "Y = y_train\n",
    "\n",
    "n_x = X.shape[0]\n",
    "m = X.shape[1]\n",
    "\n",
    "W = np.random.randn(n_x, 1) * 0.01\n",
    "b = np.zeros((1, 1))\n",
    "\n",
    "for i in range(1500):\n",
    "    Z = np.dot(W.T, X) + b\n",
    "    A = sigmoid(Z)\n",
    "    \n",
    "    cost = compute_loss(Y, A)\n",
    "    \n",
    "    dW = (1 / m) * np.dot(X, (A - Y).T)\n",
    "    db = (1 / m) * np.sum(A -Y, axis =1 , keepdims = True)\n",
    "    \n",
    "    W = W - (learning_rate * dW)\n",
    "    b = b - (learning_rate * db)\n",
    "    \n",
    "    if (i % 100 ==0):\n",
    "        print (\"Iteration : \", i, \"cost : \", cost)\n",
    "print (\"Final cost - \", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10000)\n",
      "(10000,)\n",
      "[[8971   49]\n",
      " [  44  936]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Z = np.matmul(W.T, X_test) + b\n",
    "A = sigmoid(Z)\n",
    "print(Z.shape)\n",
    "#predictions = (A > 0.5)[0,:]\n",
    "#labels = (y_test == 1)[0,:]\n",
    "#print(confusion_matrix(predictions, labels))\n",
    "\n",
    "predictions = (A>.5)[0,:]\n",
    "labels = (y_test == 1)[0,:]\n",
    "print(labels.shape)\n",
    "\n",
    "print(confusion_matrix(labels, predictions))\n",
    "\n",
    "# We got 936 of the zeroes predicted correctly and missed 49."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      0.99      9015\n",
      "        True       0.96      0.95      0.95       985\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(predictions, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hidden Layer - Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a hidden layer with 64 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost:  0.6810210349421688\n",
      "Epoch 100 cost:  0.30521416559436304\n",
      "Epoch 200 cost:  0.28392935683610476\n",
      "Epoch 300 cost:  0.2604250112383746\n",
      "Epoch 400 cost:  0.2363434609738409\n",
      "Epoch 500 cost:  0.21342069889010767\n",
      "Epoch 600 cost:  0.1925596377131004\n",
      "Epoch 700 cost:  0.17381216105618738\n",
      "Epoch 800 cost:  0.15670476159176763\n",
      "Epoch 900 cost:  0.14066741304824584\n",
      "Epoch 1000 cost:  0.12573536164273222\n",
      "Epoch 1100 cost:  0.11260831875976236\n",
      "Epoch 1200 cost:  0.10169404645757722\n",
      "Epoch 1300 cost:  0.09284464786253106\n",
      "Epoch 1400 cost:  0.08568247698510707\n",
      "Final cost -  0.07988018005220902\n"
     ]
    }
   ],
   "source": [
    "X = X_train\n",
    "Y = y_train\n",
    "\n",
    "n_x = X.shape[0]\n",
    "n_h = 64\n",
    "learning_rate = 0.05\n",
    "\n",
    "W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "b1 = np.zeros((n_h, 1))\n",
    "W2 = np.random.randn(1, n_h) * 0.01\n",
    "b2 = np.zeros((1,1))\n",
    "\n",
    "for i in range(1500):\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    cost = compute_loss(Y, A2)\n",
    "    \n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis = 1, keepdims = True)\n",
    "    \n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
    "    dW1 = (1./m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1./m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"Epoch\", i, \"cost: \", cost) \n",
    "print('Final cost - ', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8982  180]\n",
      " [  38  800]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.98      0.99      9162\n",
      "        True       0.82      0.95      0.88       838\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     10000\n",
      "   macro avg       0.91      0.97      0.93     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Z1 = np.matmul(W1, X_test) + b1\n",
    "A1 = sigmoid(Z1)\n",
    "Z2 = np.matmul(W2, A1) + b2\n",
    "A2 = sigmoid(Z2)\n",
    "\n",
    "predictions = (A2>.5)[0,:]\n",
    "labels = (y_test == 1)[0,:]\n",
    "\n",
    "print(confusion_matrix(predictions, labels))\n",
    "print(classification_report(predictions, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist['data'], mnist['target']\n",
    "X = X / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 70000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape Y\n",
    "\n",
    "digits = 10\n",
    "examples = y.shape[0]\n",
    "\n",
    "y = y.reshape(1, examples)\n",
    "\n",
    "Y_new = np.eye(digits)[y.astype('int32')]\n",
    "Y_new = Y_new.T.reshape(digits, examples)\n",
    "Y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 60000\n",
    "m_test = X.shape[0] - m\n",
    "\n",
    "X_train, X_test = X[:m].T, X[m:].T\n",
    "Y_train, Y_test = Y_new[:,:m], Y_new[:,m:]\n",
    "\n",
    "shuffle_index = np.random.permutation(m)\n",
    "X_train, Y_train = X_train[:, shuffle_index], Y_train[:, shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 32\n",
    "plt.imshow(X_train[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "Y_train[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multiclass_loss(Y, Y_hat):\n",
    "\n",
    "    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
    "    m = Y.shape[1]\n",
    "    L = -(1/m) * L_sum\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost:  9.536759414730373\n",
      "Epoch 100 cost:  0.765410456171843\n",
      "Epoch 200 cost:  0.5761323898446676\n",
      "Epoch 300 cost:  0.49415197183743803\n",
      "Epoch 400 cost:  0.4444434638304048\n",
      "Epoch 500 cost:  0.4097798352340085\n",
      "Epoch 600 cost:  0.38365617765918236\n",
      "Epoch 700 cost:  0.36289211326444343\n",
      "Epoch 800 cost:  0.34576709620603585\n",
      "Epoch 900 cost:  0.33125054642150586\n",
      "Epoch 1000 cost:  0.3187123348140507\n",
      "Epoch 1100 cost:  0.30771974318465906\n",
      "Epoch 1200 cost:  0.2979570345443281\n",
      "Epoch 1300 cost:  0.2891883602946375\n",
      "Epoch 1400 cost:  0.28123502916245446\n",
      "Epoch 1500 cost:  0.2739631566770871\n",
      "Epoch 1600 cost:  0.26726864192437266\n",
      "Epoch 1700 cost:  0.26106773700697367\n",
      "Epoch 1800 cost:  0.2552937783265869\n",
      "Epoch 1900 cost:  0.24989381082225504\n",
      "Final cost: 0.2448741623496549\n"
     ]
    }
   ],
   "source": [
    "n_x = X_train.shape[0]\n",
    "n_h = 64\n",
    "learning_rate = 1\n",
    "\n",
    "W1 = np.random.randn(n_h, n_x)\n",
    "b1 = np.zeros((n_h, 1))\n",
    "W2 = np.random.randn(digits, n_h)\n",
    "b2 = np.zeros((digits, 1))\n",
    "\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "for i in range(2000):\n",
    "\n",
    "    Z1 = np.dot(W1,X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(W2,A1) + b2\n",
    "    A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "\n",
    "    cost = compute_multiclass_loss(Y, A2)\n",
    "\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1./m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1./m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
    "    dW1 = (1./m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1./m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "\n",
    "    if (i % 100 == 0):\n",
    "        print(\"Epoch\", i, \"cost: \", cost)\n",
    "\n",
    "print(\"Final cost:\", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy, Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 954    0   10    1    1   13    9    2    5    6]\n",
      " [   0 1107    4    1    2    1    3   11    1    6]\n",
      " [   1    5  944   18    8    8    7   27   10    5]\n",
      " [   0    3   14  923    1   37    1    6   28    8]\n",
      " [   1    0   13    0  896    9   13    6   13   36]\n",
      " [  10    2    5   25    3  776   11    1   21   13]\n",
      " [   6    4   11    3   14   17  905    0   12    1]\n",
      " [   1    0   12   12    3    7    2  934   12   21]\n",
      " [   4   14   18   23   11   19    6    8  863   11]\n",
      " [   3    0    1    4   43    5    1   33    9  902]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1001\n",
      "           1       0.98      0.97      0.97      1136\n",
      "           2       0.91      0.91      0.91      1033\n",
      "           3       0.91      0.90      0.91      1021\n",
      "           4       0.91      0.91      0.91       987\n",
      "           5       0.87      0.90      0.88       867\n",
      "           6       0.94      0.93      0.94       973\n",
      "           7       0.91      0.93      0.92      1004\n",
      "           8       0.89      0.88      0.88       977\n",
      "           9       0.89      0.90      0.90      1001\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Z1 = np.matmul(W1, X_test) + b1\n",
    "A1 = sigmoid(Z1)\n",
    "Z2 = np.dot(W2, A1) + b2\n",
    "A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "\n",
    "predictions = np.argmax(A2, axis=0)\n",
    "labels = np.argmax(Y_test, axis=0)\n",
    "\n",
    "print(confusion_matrix(predictions, labels))\n",
    "print(classification_report(predictions, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy is 92 percent. In the next upload, I will try to optimize this algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
